{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e07a0cfc-195e-4183-b8ab-5bc18871e310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'user', 'id': '6507ef88423b46492ee03543', 'name': 'rayhu', 'fullname': 'Ray Hu', 'email': 'rayhu007@gmail.com', 'emailVerified': True, 'canPay': True, 'periodEnd': 1756684799, 'isPro': False, 'avatarUrl': '/avatars/e88381835e647dbe02fbd97654539e8d.svg', 'orgs': [{'type': 'org', 'id': '636025b83605bd411c1889d9', 'name': 'Stanford', 'fullname': 'Stanford AI', 'email': None, 'canPay': False, 'periodEnd': None, 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/604d2f473050a33ebb17ef51/Z-vDTyG_6-yZhzfXklqAK.jpeg', 'roleInOrg': 'contributor', 'isEnterprise': False}, {'type': 'org', 'id': '66087bf0abd8bd25eeffdf83', 'name': 'surfski', 'fullname': 'Surfski', 'email': None, 'canPay': False, 'periodEnd': None, 'avatarUrl': 'https://www.gravatar.com/avatar/4fa1051e443bad5dc9df6937156a08bf?d=retro&size=100', 'roleInOrg': 'admin', 'isEnterprise': False}], 'auth': {'type': 'access_token', 'accessToken': {'displayName': 'jupyter-note', 'role': 'write', 'createdAt': '2025-08-30T02:44:55.603Z'}}}\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import whoami\n",
    "\n",
    "print(whoami())  # confirms your saved token is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a1c4d8-969a-453a-a892-6fc6abad9863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0bafa01-c585-4d97-9e43-d87eca1f0596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d222da-c588-4abd-b273-43eb95f78966",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e96728d-62d0-46a5-a869-b0920e8d8631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use a pipeline as a high-level helper\n",
    "# from transformers import pipeline\n",
    "\n",
    "# pipe = pipeline(\n",
    "#     \"text-generation\", \n",
    "#     device=0, \n",
    "#     model=model_id\n",
    "# )\n",
    "\n",
    "# # torch_dtype=torch.bfloat16,      # bfloat16/float16 automatically if GPU supports it\n",
    "# # device=0,               # 0 = first GPU, -1 = CPU\n",
    "# # device_map=\"auto\",       # puts model on GPU if available, or "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89a3cb27-578e-4fac-becf-2d7905b8b912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb48b427ec2740a5b3280055e94d41d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,   # or torch.float16\n",
    "    device_map=\"auto\",            # puts model on GPU\n",
    "    low_cpu_mem_usage=True,\n",
    "    attn_implementation=\"sdpa\"    # memory-efficient attention\n",
    ").eval()\n",
    "\n",
    "model = model.to(device)   # or .to(\"cuda\") or .to(\"cuda:0\")\n",
    "print(\"Model device:\", model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a558c86c-2ed6-4417-878b-f27c6b026d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is 2+2? \n",
      "This is a simple math problem that can be answered with a straightforward calculation.\n",
      "2 + 2 = 4\n",
      "Therefore, the answer is 4.\n"
     ]
    }
   ],
   "source": [
    "prompt=\"User: What is 2+2?\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=300,\n",
    "    temperature=0.7,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "753a2df6-89a0-40fa-a870-e8b1ea2d0028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the difference between supervised and unsupervised learning: supervised learning is a type of machine learning in which a model is trained on labeled data, whereas unsupervised learning is a type of machine learning in which a model is trained on unlabeled data. In supervised learning, the model is trained to predict a specific output based on the input data, whereas in unsupervised learning, the model is trained to identify patterns or relationships in the data without making any predictions. This distinction is important because it affects how the model is trained, evaluated, and used in practice.\n",
      "In supervised learning, the model is trained on labeled data, meaning that the data is already annotated or labeled with the correct output. The goal of the model is to learn a mapping between the input data and the output labels, so that it can make accurate predictions on new, unseen data. Supervised learning is commonly used in applications such as image classification, speech recognition, and natural language processing.\n",
      "In contrast, unsupervised learning is used when the data is not labeled or annotated, and the goal is to identify patterns or relationships in the data without making any predictions. Unsupervised learning is often used in applications such as clustering, dimensionality reduction, and anomaly detection.\n",
      "\n",
      "Here are some key differences between supervised and unsupervised learning:\n",
      "\n",
      "* **Labeled vs. Unlabeled Data**: The most obvious difference is that supervised learning requires labeled data, while unsupervised learning uses unlabeled data.\n",
      "* **Prediction vs. Pattern Identification**: Supervised learning is used to make predictions on new data, while unsupervised learning is used to identify patterns or relationships in the data.\n",
      "* **Training Objective**: The training objective of supervised learning is to minimize the error between the predicted output and the true output, while the training objective of unsupervised learning is to identify patterns or relationships in the data.\n",
      "* **Evaluation Metric**: The evaluation metric for supervised learning is typically accuracy or mean squared error, while the evaluation metric for unsupervised learning is often clustering accuracy or silhouette score.\n",
      "\n",
      "In summary, supervised learning is used when the data is labeled and the goal is to make predictions, while unsupervised learning is used when the data is unlabeled and the goal is to identify patterns or relationships. Understanding the differences between these two types of machine learning is essential for selecting the right algorithm and evaluating its performance.\n"
     ]
    }
   ],
   "source": [
    "text_input= \"Explain the difference between supervised and unsupervised learning:\"\n",
    "inputs = tokenizer(text_input, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=500,\n",
    "    temperature=0.7,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db0c463c-d5a9-468d-82c5-8bfd0714af28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([1, 13, 128256])\n",
      "Top-5 predicted tokens: [' Superv', ' \\n', ' supervised', ' The', ' \\n\\n']\n"
     ]
    }
   ],
   "source": [
    "# Get logits (raw next-token scores)\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "    print(\"Logits shape:\", logits.shape)   # [batch, seq_len, vocab_size]\n",
    "\n",
    "# Convert last token logits to probabilities\n",
    "probs = torch.nn.functional.softmax(logits[0, -1], dim=-1)\n",
    "topk = torch.topk(probs, k=5)\n",
    "print(\"Top-5 predicted tokens:\", [tokenizer.decode([i]) for i in topk.indices.tolist()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6870396-aace-47cd-8e25-f7545d52e237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52d02d4e-f99e-4c29-a65f-7720310238be",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "⚠️ Manual only: uncomment this line to run cleanup",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m⚠️ Manual only: uncomment this line to run cleanup\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgc\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m model\n",
      "\u001b[31mRuntimeError\u001b[39m: ⚠️ Manual only: uncomment this line to run cleanup"
     ]
    }
   ],
   "source": [
    "raise RuntimeError(\"⚠️ Manual only: uncomment this line to run cleanup\")\n",
    "\n",
    "import gc, torch\n",
    "\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4491eea8-fcda-4a5d-aae5-50c9051c9754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
